export type Project = {
  slug: string;
  title: string;
  org?: string;
  timeframe?: string;

  featured?: boolean;

  // Cards + previews
  subtitle: string;
  oneLiner: string;
  tags: string[];

  impact?: string[];
  stack?: string[];
  methods?: string[];

  evaluation?: string[];
  monitoring?: string[];
  ndaSafeArtefacts?: string[];

  links?: { label: string; href: string }[];
  confidentialityNote?: string;

  // Optional deeper blocks
  problem?: string[];
  approach?: string[];
  nextSteps?: string[];
  metrics?: {
    model?: string;
    metric?: string;
    scale?: string;
    latencyOrCost?: string;
    monitoring?: string;
  };
};

export const PROJECTS: Project[] = [
  {
    slug: "warranty-claims-reduction",
    featured: true,
    title: "Warranty Claims Reduction — Propensity Scoring & Investigator Prioritisation",
    org: "JLR",
    timeframe: "2023–2024",
    subtitle: "Capacity-aware ML triage for high-value warranty interventions",
    oneLiner:
      "Ranked claims by expected reducibility so limited investigator capacity focused on the highest-value, most actionable cases.",
    tags: ["ML", "Warranty", "Decisioning", "Monitoring", "BigQuery"],

    problem: [
      "Investigators could only review a small subset of claims, so the key constraint was triage and prioritisation.",
      "Needed a pragmatic, explainable ranking that worked under real operational capacity limits.",
    ],
    approach: [
      "Built a reducibility score and validated it with time-sliced backtests to avoid leakage.",
      "Stress-tested feature sets (Claim Type, Region, etc.) and verified coverage + drift signals.",
      "Selected an operating threshold aligned to weekly capacity, with guardrails to prevent silent failure.",
    ],
    impact: [
      "Modelled multi-£m annualised opportunity (order-of-magnitude sizing)",
      "Capacity-aware operating point selection (precision/recall trade-offs) aligned to weekly throughput",
    ],
    stack: ["Python", "SQL", "BigQuery", "Tableau"],
    methods: ["Classification", "Thresholding", "Feature experiments", "Drift checks"],
    evaluation: ["Time-sliced backtests", "Segment performance (Claim Type/Region)", "Coverage + drift checks"],
    monitoring: ["Score distribution drift", "Coverage checks", "Weekly KPI tracking + guardrails"],
    ndaSafeArtefacts: ["Mock evaluation pack (charts)", "Threshold rationale one-pager", "Monitoring checklist"],
    confidentialityNote: "NDA-safe: uses synthetic examples and mock dashboards only.",
    nextSteps: [
      "Add explainability (reason codes / feature contributions) for investigator trust.",
      "Stress-test thresholds under varying capacity scenarios.",
      "Ship a lightweight reviewer UI + feedback loop to improve labels over time.",
    ],
  },

  {
    slug: "rag-platform",
    featured: true,
    title: "GenAI Knowledge Product (RAG) — Document Processing → Embeddings → Retrieval API",
    org: "JLR",
    timeframe: "2025",
    subtitle: "Config-driven RAG platform on GCP with telemetry + feedback loop",
    oneLiner:
      "Designed and implemented a reusable RAG platform (ingestion → embeddings → retrieval → grounded answer API), shipped with telemetry and human-in-the-loop quality signals.",
    tags: ["GenAI", "RAG", "GCP", "Cloud Run", "Postgres", "Observability"],

    problem: [
      "Teams needed fast, reliable access to knowledge locked inside PDFs and internal docs.",
      "Solution had to be reusable across projects with strong guardrails and monitoring.",
    ],
    approach: [
      "Built a config-driven multi-service architecture: document processing → embeddings jobs → retrieval API.",
      "Added telemetry: latency, retrieval traces, usage metrics, and lightweight feedback signals (ratings/tags).",
      "Designed prompts and data model to keep answers grounded with citations and controllable behavior.",
    ],
    impact: [
      "Reusable architecture to spin up new projects via config rather than rewriting services",
      "Telemetry and HITL loop to improve answer quality and reliability over time",
    ],
    stack: ["Cloud Run", "GCS", "Postgres", "Python", "LLM APIs"],
    methods: ["RAG", "Semantic enrichment", "Evaluation loop", "Prompting"],
    evaluation: ["Retrieval sanity checks", "Grounded-answer review workflow", "Latency + usage metrics"],
    monitoring: ["API latency + error rates", "Retrieval trace logging", "User feedback tags + ratings"],
    ndaSafeArtefacts: ["Architecture diagram", "Config YAML example", "API contract + telemetry schema"],
    confidentialityNote: "NDA-safe: architecture + patterns only; no proprietary docs or data.",
  },

  {
    slug: "warranty-forecasting-baseline",
    featured: true,
    title: "Warranty Spend Forecasting — Explainable Baseline + Feature Engineering",
    org: "JLR",
    timeframe: "2025",
    subtitle: "From trend-only forecasting to explainable drivers (age buckets, exposure, mix)",
    oneLiner:
      "Built a more granular, explainable forecasting baseline using car parc / in-warranty exposure, age buckets, and segment breakdowns to explain variance and build stakeholder trust.",
    tags: ["Forecasting", "Time Series", "XGBoost", "Warranty", "EDA"],

    problem: [
      "Existing forecasts were hard to trust because they were trend-driven and weak on explanation.",
      "Stakeholders needed drivers: vehicle mix, age effects, claim type shifts, and exposure changes.",
    ],
    approach: [
      "Built monthly aggregates and created features (rolling averages, lags) computed pre-split to avoid leakage.",
      "Compared simple baselines vs. ML models and produced residual diagnostics for 'why did we miss?' discussions.",
      "Aligned train/test to known business cadence and excluded incomplete periods from evaluation.",
    ],
    impact: [
      "Improved explainability via driver breakdowns and residual diagnostics",
      "Created a pragmatic path from baseline → richer model without losing stakeholder confidence",
    ],
    stack: ["Python", "BigQuery", "Pandas", "XGBoost", "Matplotlib"],
    methods: ["Time-based split", "Lag features", "Residual analysis", "Model comparison"],
    evaluation: ["MAE/MAPE tracking", "Backtest windows", "Segmented error analysis"],
    monitoring: ["Data completeness checks", "Feature drift watchlist", "Run logs for model comparisons"],
    ndaSafeArtefacts: ["Explainable forecast deck", "Feature schema", "Residual diagnostics screenshots"],
    confidentialityNote: "NDA-safe: show approach and diagnostics, not sensitive numbers.",
  },

  {
    slug: "web-analytics-dashboard",
    featured: true,
    title: "Product Analytics — Website Performance Dashboard + Insight Loops",
    org: "JLR",
    timeframe: "2024",
    subtitle: "Turning noisy experience data into actionable product decisions",
    oneLiner:
      "Built a dashboard and analysis workflow to connect page performance, user pain points, and stakeholder actions with clear 'what to change next' recommendations.",
    tags: ["Product Analytics", "Dashboarding", "Experimentation", "Stakeholder"],

    problem: [
      "Stakeholders had data, but not a consistent story: what’s working, what’s broken, what should change.",
    ],
    approach: [
      "Defined a metric hierarchy and created a dashboard focused on decisions (not vanity charts).",
      "Packaged findings into recurring insight loops: issue → hypothesis → measure → next action.",
    ],
    impact: [
      "Faster alignment on priority pages and changes to test",
      "Repeatable insight workflow used in stakeholder reviews",
    ],
    stack: ["SQL", "Tableau", "Python"],
    methods: ["Funnel thinking", "Cohort cuts", "Root-cause slicing"],
    evaluation: ["Stakeholder reviews", "Spot checks vs. raw extracts"],
    monitoring: ["Metric guardrails", "Weekly rollups"],
    ndaSafeArtefacts: ["Mock dashboard", "Insights deck outline", "Metric hierarchy one-pager"],
    confidentialityNote: "NDA-safe: use generic metrics and anonymised examples.",
  },

  {
    slug: "rotation-optimizer",
    title: "Graduate Rotation Optimizer — Allocation Model + End-to-End Delivery",
    org: "JLR",
    timeframe: "2024",
    subtitle: "Optimisation-backed staffing to maximise fit and business impact",
    oneLiner:
      "Designed and delivered an end-to-end allocation solution to optimise graduate placements while balancing constraints and stakeholder needs.",
    tags: ["Optimisation", "Decisioning", "Python", "Delivery"],

    impact: ["Delivered a working allocation tool with clear trade-offs and controls", "Improved transparency of constraints and placement rationale"],
    stack: ["Python", "Pandas"],
    methods: ["Optimisation", "Constraint modelling", "Scenario analysis"],
    ndaSafeArtefacts: ["Mock input/output examples", "Approach diagram", "Trade-off explanation notes"],
    confidentialityNote: "NDA-safe: show methodology and UX, not internal people data.",
  },
];

export function getProject(slug: string) {
  return PROJECTS.find((p) => p.slug === slug);
}
